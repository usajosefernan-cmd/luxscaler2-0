# Luxscaler 2.0 - AI-powered upscaling with Gemini 2.5 Flash + Imagen 3.0 v2
import os
import math
import json
import numpy as np
import google.generativeai as genai
from PIL import Image
from cog import BasePredictor, Input, Path


class Predictor(BasePredictor):
    def setup(self):
        """Inicializa la API de Gemini Imagen"""
        api_key = os.environ.get("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY no encontrada")
        genai.configure(api_key=api_key)
        
        # Modelo Imagen 3.0 para generaciÃ³n
        self.model = genai.GenerativeModel('imagen-3.0-generate-001')
    
    def predict(
        self,
        image: Path = Input(description="Input image (any resolution)"),
        scale_factor: int = Input(description="Scale factor (2x, 3x, 4x, 8x)", choices=[2, 3, 4, 8], default=4),
        gemini_api_key: str = Input(description="Gemini API Key (optional)", default="")
    ) -> Path:
        
        # Configurar API key si se proporciona
        if gemini_api_key:
            genai.configure(api_key=gemini_api_key)
            self.setup()
        
        # Cargar imagen original
        input_img = Image.open(image).convert('RGB')
        input_width, input_height = input_img.size
        
        # Calcular target_resolution basado en scale_factor
        # El lado mÃ¡s largo de la imagen se multiplicarÃ¡ por scale_factor
        longest_side = max(input_width, input_height)
        target_resolution = longest_side * scale_factor
        
        print(f"Input: {input_width}x{input_height}")
        print(f"Scale factor: {scale_factor}x")
        print(f"Target: {target_resolution}px (longest side)")
        
        # EL MEGA-PROMPT MAESTRO DE LUXIFIER
        master_prompt = f"""
**ROL DEL SISTEMA & OBJETIVO FINAL:**
NO ERES un editor de imÃ¡genes. ERES un motor de **reconstrucciÃ³n generativa de ultra-alta fidelidad** (basado en protocolos tipo "Magnific/Deep Upscale").
Tu objetivo es tomar la imagen de entrada como un simple "mapa de guÃ­as" (identidad y composiciÃ³n) y **VOLVER A SOÃ‘ARLA** desde cero a una resoluciÃ³n masiva de {target_resolution}px,
inventando detalles microscÃ³picos que no existen en el archivo original pero que son biolÃ³gica y materialmente obligatorios para el realismo.

**DIRECTIVAS DE SALIDA OBLIGATORIAS:**
1. **ResoluciÃ³n Objetivo:** Escala la imagen hasta que su lado mÃ¡s largo sea exactamente **{target_resolution} pÃ­xeles**.
2. **Formato:** MantÃ©n estrictamente la relaciÃ³n de aspecto original.

**PROTOCOLO DE EJECUCIÃ“N "ALUCINACIÃ“N CONTROLADA" (ESTRICTO):**

**FASE 1: EL ANCLA DE IDENTIDAD (FIDELIDAD MÃXIMA)**
* Analiza la estructura Ã³sea, los rasgos faciales y la expresiÃ³n del sujeto.
* **REGLA INVIOLABLE:** La geometrÃ­a facial y la identidad del sujeto NO PUEDEN CAMBIAR. Ni fondo, ni tono de foto ni ropa. Usa la imagen original como una restricciÃ³n geomÃ©trica rÃ­gida.

**FASE 2: MOTOR DE ALUCINACIÃ“N DE TEXTURA (INVENCIÃ“N MÃXIMA)**
* **PROHIBIDO SUAVIZAR.** Si un Ã¡rea de la imagen original (especialmente piel, tela o pelo) estÃ¡ borrosa, empastada o carece de definiciÃ³n, 
DEBES interpretar esto como "datos faltantes" que necesitan ser rellenados con generaciÃ³n sintÃ©tica de alta frecuencia.

* **InyecciÃ³n de Detalle BiolÃ³gico (Piel):**
  * **NO GENERES "PIEL PERFECTA". GENERA TEJIDO VIVO.**
  * Debes sintetizar ("alucinar") una estructura compleja de poros individuales, variaciones en la capa cÃ³rnea, micro-arrugas dinÃ¡micas alrededor de los ojos/boca
    y, crucialmente, **vello facial imperceptible (vellus hair)** en las mejillas y frente para dar realismo tÃ¡ctil.
  * AÃ±ade vascularizaciÃ³n sutil y pigmentaciÃ³n irregular. La piel debe tener "grano" orgÃ¡nico al hacer zoom al 100%.

* **InyecciÃ³n de Detalle Material (Ojos y Ropa):**
  * **Ojos:** Genera una textura de iris fibrosa y compleja. AÃ±ade un "catchlight" (reflejo de luz) nÃ­tido y humedad en el lagrimal y la lÃ­nea de agua.
  * **Ropa:** Reconstruye el tejido hilo por hilo. Que se note la diferencia entre algodÃ³n, lana o seda.

**FASE 3: SIMULACIÃ“N Ã“PTICA DE GAMA ALTA (EL "LOOK")**
* **Sensor Virtual:** Simula la captura con un respaldo digital de Formato Medio (Phase One IQ4, 150MP). 
  Esto implica una profundidad de color y un rango dinÃ¡mico extremos.
* **Lente y Foco:** Simula una lente "Prime" ultra-rÃ¡pida (f/1.2). Aplica un enfoque crÃ­tico y "rabioso" (mÃ¡xima acutancia) en los ojos y la textura de la piel.
  Todo lo que estÃ© ligeramente fuera de ese plano focal debe caer en un bokeh cremoso y progresivo.

**FASE 4: REILUMINACIÃ“N VOLUMÃ‰TRICA (ESCULTURA 3D)**
* Si la luz original es plana, destrÃºyela.
* Implementa una iluminaciÃ³n cinematogrÃ¡fica (ej. "Book Light" lateral suave pero direccional) que cree micro-sombras dentro de los nuevos poros y arrugas
  que has generado, esculpiendo el rostro con volumen tridimensional dramÃ¡tico (claroscuro).

**RESULTADO FINAL ESPERADO:**
Una imagen de {target_resolution}px que, al ser inspeccionada con lupa al 100%, no muestre artefactos de interpolaciÃ³n, 
sino una densidad abrumadora de informaciÃ³n biolÃ³gica y material sintÃ©tica, indistinguible de una fotografÃ­a RAW de 100 megapÃ­xeles.
"""
        
        try:
            print("ðŸŽ¨ Generando imagen con Imagen 3.0...")
            
            # Llamada a Imagen 3.0 con la imagen original + el mega-prompt
            response = self.model.generate_content(
                [master_prompt, input_img]
            )
            
            # Extraer imagen generada
            output_image = None
            if hasattr(response, 'parts'):
                for part in response.parts:
                    if hasattr(part, 'inline_data'):
                        from io import BytesIO
                        output_image = Image.open(BytesIO(part.inline_data.data))
                        break
            
            if output_image is None:
                raise Exception("No se pudo extraer imagen del response de Imagen 3.0")
            
            # Asegurar que el lado mÃ¡s largo sea el target
            width, height = output_image.size
            if max(width, height) != target_resolution:
                print(f"âš ï¸ Ajustando resoluciÃ³n de {width}x{height} a {target_resolution}px...")
                if width > height:
                    new_w = target_resolution
                    new_h = int(height * (target_resolution / width))
                else:
                    new_h = target_resolution
                    new_w = int(width * (target_resolution / height))
                output_image = output_image.resize((new_w, new_h), Image.Resampling.LANCZOS)
            
            # Guardar resultado
            output_path = "/tmp/luxified_output.png"
            output_image.save(output_path, quality=95, optimize=True)
            
            print(f"âœ… Done! Output: {output_image.width}x{output_image.height}px")
            return Path(output_path)
            
        except Exception as e:
            print(f"âŒ Error en generaciÃ³n: {e}")
            # Fallback: escalar con Lanczos de alta calidad
            print("âš ï¸ Usando fallback: Lanczos interpolation")
            
            width, height = input_img.size
            if width > height:
                new_w = target_resolution
                new_h = int(height * (target_resolution / width))
            else:
                new_h = target_resolution
                new_w = int(width * (target_resolution / height))
            
            fallback_img = input_img.resize((new_w, new_h), Image.Resampling.LANCZOS)
            fallback_path = "/tmp/luxified_output.png"
            fallback_img.save(fallback_path, quality=95)
            
            return Path(fallback_path)
